# 标题待定

工作用技术栈记录

参考技术栈为开源项目https://gitee.com/xiaoxiangopen/analysis

## Flume数据采集

### 前言

公司平台每日会产生大量日志，一般为流式数据，如查询、搜索引擎pv等，处理这些日志需要特定日志系统，需要具备以下特征：

1. 应用系统与分析系统的桥梁，解耦关联
2. 近实时的在线分析系统，类似Hadoop的离线分析系统
3. 高可扩展性，如数据量增加时，可以通过增加节点进行水平扩展

**符合条件的开源日志系统**

- scribe（facebook）
- chukwa（apache）
- flume（cloudera）

### 简介

分布式、可靠、高可用的海量日志聚合系统。（日志收集框架）

- 支持在系统中定制各类数据发送方，用于收集数据；
- 提供对数据的简单处理，写到各种数据接收方（比如文本、HDFS、Hbase等）的能力。

**可靠性**

节点故障时，能将日志传送到其他节点不会丢失；

提供三种级别可靠性：

- end-to-end 

  收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。

- Store on failure 

  也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送

- Besteffort 

  数据发送到接收方后，不会进行确认

**可恢复性**

靠Channel，推荐使用FileChannel，事件持久化在本地文件系统里（性能较差）



### 核心概念

https://www.cnblogs.com/qingyunzong/p/8994494.html



### 安装

- 前提：JDK环境
- 下载：http://archive.apache.org/dist/flume/ 当前为[apache-flume-1.10.1-bin.tar.gz](http://www.apache.org/dyn/closer.lua/flume/1.10.1/apache-flume-1.10.1-bin.tar.gz)

#### Win

目标：创建一个简单例子监听44444端口的输入并在console中输出

- 解压缩，为了方便后续，配置环境变量

  ```shell
  FLUME_HOME=#flume根目录
  # path添加 %FLUME_HOME%\conf;%FLUME_HOME%\bin;
  ```

  ![image-20220830150937322](https://strangest.oss-cn-shanghai.aliyuncs.com/markdown/202208301509346.png)

  可以通过控制台输入指令测试

  ```shell
  flume-ng version
  ```

  ![image-20220830151018158](https://strangest.oss-cn-shanghai.aliyuncs.com/markdown/202208301510183.png)

- 在conf目录下创建test.conf

  ```properties
  # 参考flume-conf.properties.template
  # 定义这个 agent 中各组件的名字 r
  a1.sources = r1 
  a1.sinks = k1 
  a1.channels = c1 
  # 描述和配置 source 组件：r1 
  a1.sources.r1.type = netcat 
  a1.sources.r1.bind = localhost 
  a1.sources.r1.port = 44444 
  # 描述和配置 sink 组件：k1 
  a1.sinks.k1.type = logger 
  # 描述和配置channel组件，此处使用是内存缓存的方式 
  a1.channels.c1.type = memory 
  a1.channels.c1.capacity = 1000 
  a1.channels.c1.transactionCapacity = 100 
  # 描述和配置 source channel sink 之间的连接关系 
  a1.sources.r1.channels = c1 
  a1.sinks.k1.channel = c1 
  ```

- 控制台进入bin目录，运行指令启动

  ```shell
  # 任选其一
  flume-ng agent --conf ../conf --conf-file ../conf/test.conf --name a1 -property flume.root.logger=INFO,console
  flume-ng agent --conf %FLUME_HOME%/conf --conf-file %FLUME_HOME%/conf/test.conf --name a1 -property flume.root.logger=INFO,console
  # powershell 运行  利用环境变量
  flume-ng.cmd agent --conf $env:FLUME_HOME/conf --conf-file $env:FLUME_HOME/conf/test.conf --name a1 -property "flume.root.logger=INFO,console"
  flume-ng agent -conf $env:FLUME_HOME/conf -conf-file $env:FLUME_HOME/conf/test.conf -name a1 -property "flume.root.logger=INFO,console"
  ```

  ![image-20220830153507174](https://strangest.oss-cn-shanghai.aliyuncs.com/markdown/202208301535200.png)

  虽然有报错，但从端口查看是已经启动了

- 启动另一个控制台，使用telnet连接到44444端口并发送信息Hello World!

  ```shell
  telnet localhost 44444
  ```

  ![image-20220830153920744](https://strangest.oss-cn-shanghai.aliyuncs.com/markdown/202208301539764.png)

  查看flume日志（flume.log，在哪个目录运行指令就在哪个目录）

  ![image-20220830153951263](https://strangest.oss-cn-shanghai.aliyuncs.com/markdown/202208301539290.png)

> telnet需要开启后才能用
>
> https://help.aliyun.com/document_detail/40796.html



##### 1.10.1版本当前配置不显示控制台日志

1.9.0可以显示，从显示内容来看因为配置未生效

原因是1.9之前使用log4j2.properties文件配置，1.10使用log4j2.xml配置，用于对应log4j 2.X版本。

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!--...-->
<Configuration status="ERROR">
  <Properties>
    <Property name="LOG_DIR">.</Property>
  </Properties>
  <Appenders>
    <Console name="Console" target="SYSTEM_ERR">
      <PatternLayout pattern="%d (%t) [%p - %l] %m%n" />
    </Console>
    <RollingFile name="LogFile" fileName="${LOG_DIR}/flume.log" filePattern="${LOG_DIR}/archive/flume.log.%d{yyyyMMdd}-%i">
      <PatternLayout pattern="%d{dd MMM yyyy HH:mm:ss,SSS} %-5p [%t] (%C.%M:%L) %equals{%x}{[]}{} - %m%n" />
      <Policies>
        <!-- Roll every night at midnight or when the file reaches 100MB -->
        <SizeBasedTriggeringPolicy size="100 MB"/>
        <CronTriggeringPolicy schedule="0 0 0 * * ?"/>
      </Policies>
      <DefaultRolloverStrategy min="1" max="20">
        <Delete basePath="${LOG_DIR}/archive">
          <!-- Nested conditions: the inner condition is only evaluated on files for which the outer conditions are true. -->
          <IfFileName glob="flume.log.*">
            <!-- Only allow 1 GB of files to accumulate -->
            <IfAccumulatedFileSize exceeds="1 GB"/>
          </IfFileName>
        </Delete>
      </DefaultRolloverStrategy>
    </RollingFile>
  </Appenders>

  <Loggers>
    <Logger name="org.apache.flume.lifecycle" level="info"/>
    <Logger name="org.jboss" level="WARN"/>
    <Logger name="org.apache.avro.ipc.netty.NettyTransceiver" level="WARN"/>
    <Logger name="org.apache.hadoop" level="INFO"/>
    <Logger name="org.apache.hadoop.hive" level="ERROR"/>
    <Root level="INFO">
      <AppenderRef ref="LogFile" />
    </Root>
  </Loggers>
</Configuration>
```

根据配置，可以看到logger里引入的appender才能生效，而当前虽然有console的配置，但并没有加入生效行列。

所以修改loggers配置为

```xml
<Loggers>
    <Logger name="org.apache.flume.lifecycle" level="info"/>
    <Logger name="org.jboss" level="WARN"/>
    <Logger name="org.apache.avro.ipc.netty.NettyTransceiver" level="WARN"/>
    <Logger name="org.apache.hadoop" level="INFO"/>
    <Logger name="org.apache.hadoop.hive" level="ERROR"/>
    <Root level="INFO">
        <AppenderRef ref="LogFile" />
        <AppenderRef ref="Console" />
    </Root>
</Loggers>
```

然后简化指令启动即可

```shell
flume-ng agent  -conf $env:FLUME_HOME/conf -conf-file $env:FLUME_HOME/conf/test.conf -name a1
```



##### test.conf配置文件

通过一个配置文件来配置Agent。

test.conf：单节点Flume配置，放在Flume根目录的conf目录下

```shell
# 命名为a1的Agent的组件
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# 配置Source
a1.sources.r1.type = netcat
a1.sources.r1.bind = 0.0.0.0
a1.sources.r1.port = 44444
# 配置Sink
a1.sinks.k1.type = logger
# 配置Channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100
# 配置绑定关系 channel与source和sink
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
```

- 一个配置文件中可以配置多个Agent，一个Agent中可以包含多个Source、Sink、Channel。
- 一个Source可以绑定到多个通道，一个Sink只能绑定到一个通道。





## Hadoop



## Flink





# kafka

## 简介

是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统），常见可以用于web/nginx日志、访问日志，消息服务等。

主要应用场景：日志收集系统和消息系统



## 安装

### Win

- 安装Zookeeper，下载地址https://mirrors.bfsu.edu.cn/apache/zookeeper/  

  这里选择版本 3.8.0对应的apache-zookeeper-3.8.0-bin.tar.gz 并解压缩

  > 从3.5.5开始，带有bin名称的包才能解压出直接运行的包

  - 进入conf目录，复制一份zoo_sample.cfg  重命名为zoo.cfg
  - 进入bin目录，运行zkServer.cmd即可

  > 现在的kafka存在内置zookeeper版本的启动，所以这一步可以省略

- 下载kafka，下载地址https://mirrors.bfsu.edu.cn/apache/kafka/ 

  这里选择版本3.2.1对应的kafka_2.13-3.2.1.tgz 并解压缩

- 进入bin/windows目录，启动zookeeper，进行这一步则不用走第一步

  ```powershell
  .\zookeeper-server-start.bat ..\..\config\zookeeper.properties
  ```

- 还在bin/windows目录，启动kafka

  ```powershell
  .\kafka-server-start.bat ..\..\config\server.properties
  ```

  







